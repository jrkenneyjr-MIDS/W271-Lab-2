---
title: "Lab 02"
author: "Alex Yang, John Kenney, Ram Balasubramanian"
subtitle: "w271"
date: "Oct 12, 2017"
output: pdf_document
fontsize: 11pt
geometry: margin=0.75in
---


#SECTION - 3  STATISTICAL MODELING:
Section 3: Statistical Modeling. Start the section summarizing the key results - what variables, if any, are the key predictors of the year 2016 contribution? What are the key techniques you have experimented? What method did you use in your final model? How did you choose the final model? What model performance criteria did you use to choose the final model? What statistical infernece did you perform? Explain them. Comment on statistical significance vs. economic significance.

##3.1 KEY RESULTS:  
We found that the best way to predict the level of contribution in 2016 for a particular person is to look at their level of contribution in 2015 and how often they have given in the past. Here is why we think this makes sense: we believe alumni-giving would be influenced by factors like connectedness to the university (Alumni event attendance, proximity to univesity), affluence (utilizing proxy measures like class year, major, next degree, marital status), exposure to marketing materials about the university, news related to the university etc.   However many of these factors do not change much (or at all) in the time horizon for which we were provided data (even if they changed, we were not provided the change information) - which basically means that we should be able to witness the influence of these factors in past years' giving information. Said another way these factors combined to result in a certain pattern of giving in each of the years 2012 - 2015;  so when we want to predict 2016 giving, we can simply use the past giving which encapsulates all the factors that influence someone to give.  

The functional form of our chosen model for predicting 2016 is:  

$log(\frac{\hat{\pi}_{j}}{\hat{\pi}_{base}}) = \beta_{0j} +\sum_{k=1}^{4}\beta_{kj} \cdot FY15_{k}+\beta_{4j}\cdotYearsGiven$  

where $FY15_k$ is the category of giving in 2015; and $YearsGiven$ is the number of years (between 2012 and 2015) that the person contributed; $\hat{\pi}_j$ is the probability of being in the $j^{th}$ category; $\hat{\pi}_{base}$ is the probability of being the base category (in our case this is the [0,1) category or "non-givers").  

We went with a multinomial logistic regression technique because the target variable is multinomial.  Let's run through the assumptions behind a multinomial logistic regression to make sure that it is applicable here:  
1. The target variable is a categorical variable
2. While we do not have additional information about the exact sampling technique employed, since it is mentione that it is a carefully selected sample - we assume that it is an independent, identically distributed sample.
3. No perfect collinearity (we will address this by the choice of dependent variables)
4. Linearity - log odds of the the dependent variable is linearly related to the independent variables (this holds by the structural assumption)
5. No complete separation (we don't observe any, but we can also rely on the R software to identify this for us)

##3.1.1 MODEL INTERPRETATION


##3.2 OTHER MODELS AND TECHNIQUES ATTEMPTED:  



##3.3 MODEL EVALUATION & SELECTION:


##3.4 STATISTICAL INFERENCE:


##3.5 STATISTICAL SIGNIFICANCE VS. ECONOMIC SIGNIFICANCE



```{r message=FALSE, warning=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
#Libraries required 
library(car)
library(dplyr)
library(Hmisc)#Used by author for 3D plotting
library(ggplot2)
library(gridExtra)
library(effsize) #Used to calculate Cohen's D for T-Test
library(aod)    #Used for effect size of the logit model
library(mcprofile) #Used for confidence intervals
library(package = MASS)  # Location of parcoord() function
library(vcd)
library(data.table)
library(stargazer)
library(nnet)
library(ordinal)
library(caret)

#can delete this line below if dataset is already in workspace
#otherwise, run SECTION1.Rmd file (need this process of storing the data frame and
#loading it again if we knit the SECTION files separately)

load("dt_dataframe.Rda")

#Renaming to shorter names - to fit display
names(dt)[names(dt)=="FY15GivingCat"] = "FY15"
names(dt)[names(dt)=="FY14GivingCat"] = "FY14"
names(dt)[names(dt)=="FY13GivingCat"] = "FY13"
names(dt)[names(dt)=="FY12GivingCat"] = "FY12"
names(dt)[names(dt)=="AttendenceEvent"] = "Event"
names(dt)[names(dt)=="ClassYearCat"] = "Class"
names(dt)[names(dt)=="Marital.Status"] = "MS"
names(dt)[names(dt)=="NextDegCat"] = "NextDeg"


```


```{r}
set.seed(1234)
train_index = createDataPartition(dt$FY16GivingCat, p=0.8, list=FALSE, times=1)
dt_train = dt[train_index]
dt_test = dt[-train_index]
#verify that the test and train are in the same proportions for 2016 categories
# xtabs(~FY16GivingCat, data=dt_train)
# xtabs(~FY16GivingCat, data=dt_test)
# round(prop.table(xtabs(~FY16GivingCat, data=dt_train)),2)
# round(prop.table(xtabs(~FY16GivingCat, data=dt_test)),2)
```




```{r}

PredAcc = function(data_set, mod){
  #Function to  evaluate accuracy of model
    #data_test: a data frame or table that contains  data
    #mod: model fit on data

  #Predict the responses given model
  
  dep = names(mod$model[1])  #Name of Dependent Variable
  act = data_set[, ..dep]   #List of Actual Observed Outcomes
  if (class(mod)[1] == "glm"){
    prob = predict(mod, newdata = data_set, type = "response") #Probability Binary is True
    pred = ifelse(prob>0.5, 1, 0)       #Predicted Result
  }else if (class(mod)[1] == "multinom"){
    prob = predict(mod, newdata = data_set, type = 'probs')  #Probability of each category
    pred = colnames(prob)[max.col(prob, ties.method = "random")]  #Category of highest probability
  }else if (class(mod)[1] == 'clm'){
    pred = predict(mod, newdata = data_set, type = 'class')  #Category of highest probability
  }
  
  results = data.frame(predicted = pred, actual = act)
  #If we decide not to use Confusion Matrix...
  #accuracy = round(mean(test.act == test.pred),3)  #Part of confusionMatrix             
  #GenXtab(dframe = results, x1 = results[,1], x2 = results[,2], nlist = c("Predicted","Actual"))                       
  #paste("Overall Prediction Accuracy = ", accuracy)
  
  confusionMatrix(results[,1],results[,2], positive = '1') #Analysis of Prediction Accuracy Stats
}

Accuracy= function(CM_train, CM_test, model_name){
  #Takes in 2 confusion matrices - one for train and 1 for test
  # and returns a row with accuracy value for test and train sets
  round(data.frame(row.names = model_name, TrainAcc = CM_train$overall[1], 
                   TestAcc = CM_test$overall[1]),2)
  
}

PrintModel=function(mod){
  #basically printing the summary function - with fewer decimals
  x = summary(mod)
  coefs = round(x$coefficients,2)
  
  print((x$call)$formula)
  print("coeffs")
  print(coefs)
  if (class(mod)!="clm"){
    stderr = round(x$standard.errors,2)
    print("standard errors")
    print(stderr)
  }
  
  
}

```





```{r message=FALSE}
#models for determining category - using 2016giving category as function of 
#2015 giving category 

#Start with the simplest model. Assume everything 
model.fit2a = multinom(FY16GivingCat~FY15, data=dt_train, model = TRUE, trace=FALSE)
#summary(model.fit2a)
PrintModel(model.fit2a)
an1 = Anova(model.fit2a, test="LR")
names(an1)
an1

CMTr = PredAcc(dt_train, mod=model.fit2a)
CMTe = PredAcc(dt_test, mod=model.fit2a)
ac_table = Accuracy(CMTr, CMTe, "model.fit2a")

#Naive model - just use FY15 category to predict 2016 - we should be able to do better than this
pred_val = dt_train$FY15
act_val = dt_train$FY16GivingCat
results = data.frame(predicted=pred_val, actual=act_val)
CMTr = confusionMatrix(results[,1],results[,2], positive='1')

pred_val = dt_test$FY15
act_val = dt_test$FY16GivingCat
results = data.frame(predicted=pred_val, actual=act_val)
CMTe = confusionMatrix(results[,1],results[,2], positive='1')
ac_table = rbind(ac_table,Accuracy(CMTr, CMTe, "naive_model"))

#uSe all historical giving categories (massive collinearity) 
model.fit2b = multinom(FY16GivingCat~FY15+FY14+FY13+FY12, data=dt_train, model = TRUE, trace=FALSE)
#summary(model.fit2b)
PrintModel(model.fit2b)
Anova(model.fit2b, test="LR")
CMTr = PredAcc(dt_train, mod=model.fit2b)
CMTe = PredAcc(dt_test, mod=model.fit2b)
ac_table = rbind(ac_table, Accuracy(CMTr, CMTe, "model.fit2b"))
```


```{r message=FALSE, warning=FALSE}

#Address collinearity by using 2015 giving category - substituting yearsgiven instead of each year's category
model.fit2c = multinom(FY16GivingCat~FY15+YearsGiven, data=dt_train, model=TRUE, trace=FALSE)
#summary(model.fit2c)
PrintModel(model.fit2c)
Anova(model.fit2c, test="LR")
CMTr = PredAcc(dt_train, mod=model.fit2c)
CMTe = PredAcc(dt_test, mod=model.fit2c)
ac_table= rbind(ac_table, Accuracy(CMTr, CMTe, "model.fit2c"))


#Add other variables that seemed significant in the EDA.  We believe that the impact of these
#variables is already encapsulated in the FY15GivingCategory (see writeup for rationale)
model.fit2d = multinom(FY16GivingCat~FY15+YearsGiven+Event+NextDeg+Gender, data=dt_train, model=TRUE, trace=FALSE)
#summary(model.fit2d)
PrintModel(model.fit2d)
Anova(model.fit2d, test="LR")
CMTr = PredAcc(dt_train, mod=model.fit2d)
CMTe = PredAcc(dt_test, mod=model.fit2d)
ac_table = rbind(ac_table, Accuracy(CMTr, CMTe, "model.fit2d"))
```

###Model Specification:  
$log(\frac{\hat{\pi}_{[1,100)}}{\hat{\pi}_{[0,1)}}) = -2.87 + 1.10 \cdot FY15[1,100) -0.65\cdot FY15[100,250)-15.24\cdot FY15[250,500)-12.49\cdot FY15[500,20000) + 0.8\cdot YearsGiven$  

###



```{r message=FALSE, warning=FALSE}
#Below are the class of models without using prior year giving info
model.fit3a = multinom(FY16GivingCat~NextDeg+Event+Class+MS+Gender, data=dt_train, model=TRUE, trace=FALSE)

#summary(model.fit3a)
PrintModel(model.fit3a)
Anova(model.fit3a, test="LR")
CMTr = PredAcc(dt_train, mod=model.fit3a)
CMTe = PredAcc(dt_test, mod=model.fit3a)
ac_table =  rbind(ac_table,Accuracy(CMTr, CMTe, "model.fit3a"))

```

```{r message=FALSE, warning=FALSE}
library(ordinal)
model.fit4a = clm(FY16GivingCat~FY15+YearsGiven, data=dt_train, model=TRUE, trace=FALSE)
names(model.fit4a)
PrintModel(model.fit4a)
Anova(model.fit4a, test="F")
CMTr = PredAcc(dt_train, mod=model.fit4a)
CMTe = PredAcc(dt_test, mod=model.fit4a)
ac_table =  rbind(ac_table,Accuracy(CMTr, CMTe, "model.fit4a"))


model.fit4b = clm(FY16GivingCat~FY15+YearsGiven, data=dt_train, model=TRUE, trace=FALSE)
PrintModel(model.fit4b)
Anova(model.fit4b, test="F")
CMTr = PredAcc(dt_train, mod=model.fit4b)
CMTe = PredAcc(dt_test, mod=model.fit4b)
ac_table =  rbind(ac_table,Accuracy(CMTr, CMTe, "model.fit4b"))

print("Model Accuracy Comparison")
print(ac_table)
```